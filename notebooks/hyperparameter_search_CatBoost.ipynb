{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Finetuning with RandomizedSeachCV\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ggf muss Pfad angepasst werden\n",
    "os.chdir(\"{}/..\".format(os.getcwd()))\n",
    "os.getcwd()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, linear_model, metrics\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split, cross_validate\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Loading the whole training set and adding the column \"totalScannedItems\" by calling `add_new_features` defined in utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\", sep=\"|\")\n",
    "df = add_new_features(df)\n",
    "sum_frauds, sum_non_frauds  = len(df[df.fraud == 1]), len(df[df.fraud == 0])\n",
    "train_y = df.fraud\n",
    "train_x = df.drop(columns=['fraud'])\n",
    "\n",
    "train_pool = Pool(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data for validation\n",
    "df_fit = pd.read_csv(\"data/train_new.csv\", sep=\"|\")\n",
    "df_fit = add_new_features(df_fit)\n",
    "df_fit_y = df_fit.fraud\n",
    "df_fit_x = df_fit.drop(columns=['fraud'])\n",
    "test_train_pool = Pool(df_fit_x, df_fit_y)\n",
    "\n",
    "# Validation Data\n",
    "df_val = pd.read_csv(\"data/val_new.csv\", sep=\"|\")\n",
    "df_val = add_new_features(df_val)\n",
    "df_val_y = df_val.fraud\n",
    "df_val_x = df_val.drop(columns=['fraud'])\n",
    "test_val_pool = Pool(df_val_x, df_val_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring functions\n",
    "Defining multiple scores which should be tracked in the HyperParamSearch Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'FBeta': metrics.make_scorer(metrics.fbeta_score, beta=0.5172)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the paramteres which should be tuned\n",
    "To tune the hyperparameters, i looked into the [documentation here](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster). `randint` can be used for integer values, for float values, use `uniform`. \n",
    "\n",
    "You can also use a Grid search on single parameters to get a feeling for a good interval. If you want to try only two possibilities, you can create a list like for the `scale_pos_weight` parameter.\n",
    "\n",
    "**Note: For the classifiers which work without gpu support, you can probably set a parameter n_jobs=-1 to use all processors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": randint(100, 1000),  # default 3\n",
    "    \"learning_rate\" :  uniform(1e-6, 1e-2),\n",
    "    \"depth\" : randint(1, 10),\n",
    "    \"l2_leaf_reg\" : uniform(1e-5,10),\n",
    "    \"border_count\" : randint(1,128) #Set it to value of 1-10 might help control the update.\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a classifier with some default values\n",
    "Not all paramters of a classifier should be fine tuned. For SVM for example, the `kernel`-paramter should be set manually. In the case of xgboost, some things like the objective, the booster and the tree method should not be tuned. The choice of paramters depend on the specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(loss_function=\"CrossEntropy\", task_type=\"GPU\", logging_level=\"Silent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some RandomizedSeach parameters\n",
    "- cv = cross validation: 3 is the standard value. This is enough and should not be touched\n",
    "- param_distribution: The params defined two cells above\n",
    "- scorer: The Scorere defined under \"scoring functions\" AUC and Fbeta are currently the best.\n",
    "- return_train_score: Doesnt affect the hyper param search\n",
    "- refit : Here, you can adress a score with the name, given in the dictionary. \n",
    "- n_jobs : -1 to use all cpus\n",
    "- n_iter : depends on number of params. For 9 params, i suggest a value above 20k. For less paramters 10k could be a good value.\n",
    "\n",
    "Further informations: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  4.0min finished\n",
      "/home/lukas/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(model, scoring=scoring, param_distributions=params, random_state=42, n_iter=10,\n",
    "                            cv=3, verbose=1, n_jobs=1, return_train_score=True,refit='AUC')\n",
    "search.fit(train_x, train_y)\n",
    "results = search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Fix Split: \n",
      "DMC Score: 90  ---  Normalized DMC Score: 0.2393617021276596, \n",
      "\n",
      "Results Cross Validation: \n",
      "DMC Score: 34.0  ---  Normalized DMC Score: 0.0903758865248227 \n"
     ]
    }
   ],
   "source": [
    "scorings = {\"DMC\" : own_scorer, \"DMC_Norm\" : own_scorer_normalized}\n",
    "xgbo = search.best_estimator_\n",
    "result_dict = test_classification(xgbo,df_train=df_fit, df_val=df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show false predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "      <th>totalScannedItems</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>1486</td>\n",
       "      <td>57.13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "87           1                    1486       57.13              4   \n",
       "\n",
       "    scansWithoutRegistration  quantityModifications  \\\n",
       "87                         1                      1   \n",
       "\n",
       "    scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "87                   0.015478        0.038445                  0.173913   \n",
       "\n",
       "    fraud  totalScannedItems  prediction  probablity  \n",
       "87      0               23.0         1.0       0.562  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = result_dict['dataframe']\n",
    "res_df[(res_df.prediction != res_df.fraud)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f8b03dde6d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
