{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\theur\\\\Documents\\\\Uni\\\\Master\\\\dmc19'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# ggf muss Pfad angepasst werden\n",
    "os.chdir(\"{}/..\".format(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, linear_model, metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split, cross_validate\n",
    "#from scripts.utils import own_scorer, calc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate multiple scores\n",
    "def calc_scores(y_test, y_pred):\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    f2_score = (0 if all(y_pred == 0) else metrics.fbeta_score(y_test, y_pred, beta=2))\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "\n",
    "    return accuracy, f2_score, dmc_score/len(y_test), confusion_matrix\n",
    "\n",
    "# Normalized DMC Score for usage as scorer\n",
    "def own_scorer_normalized(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    confusion_matrix = metrics.confusion_matrix(ground_truth, prediction)\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "    return dmc_score/len(ground_truth)\n",
    "\n",
    "# DMC Score for usage as scorer\n",
    "def own_scorer(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    confusion_matrix = metrics.confusion_matrix(ground_truth, prediction)\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "    return dmc_score\n",
    "# F2 Score for usage as scorer\n",
    "def own_f2_score(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    return 0 if all(prediction == 0) else metrics.fbeta_score(ground_truth, prediction, beta=2)\n",
    "\n",
    "\n",
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate],\n",
    "                results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading train data and add feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data:  (1503, 10) Shape of val data:  (376, 10)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/extended_train.csv\", sep=\"|\")\n",
    "df_y = df_train.fraud\n",
    "df_X = df_train.drop(['fraud'], axis=1)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(df_X, df_y, test_size=0.2)\n",
    "\n",
    "print(\"Shape of train data: \", train_x.shape, \"Shape of val data: \", val_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a quantile scaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data:  (1503, 10) Shape of val data:  (376, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>totalScannedLineItems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>0.648859</td>\n",
       "      <td>0.640472</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.667904</td>\n",
       "      <td>0.483474</td>\n",
       "      <td>0.389940</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2.777778e-01</td>\n",
       "      <td>0.951567</td>\n",
       "      <td>0.737107</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>0.490378</td>\n",
       "      <td>0.387489</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.286281</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2.222222e-01</td>\n",
       "      <td>0.745408</td>\n",
       "      <td>0.394678</td>\n",
       "      <td>0.704134</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.074635</td>\n",
       "      <td>0.622208</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>7.777778e-01</td>\n",
       "      <td>0.624107</td>\n",
       "      <td>0.889571</td>\n",
       "      <td>0.898635</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>2.777778e-01</td>\n",
       "      <td>0.082492</td>\n",
       "      <td>0.484902</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.588309</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.890838</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "1550  9.999999e-01                0.648859    0.640472       0.722222   \n",
       "466   2.777778e-01                0.951567    0.737107       0.111111   \n",
       "273   1.000000e-07                0.286281    0.228311       1.000000   \n",
       "550   1.000000e-07                0.074635    0.622208       0.666667   \n",
       "673   2.777778e-01                0.082492    0.484902       0.444444   \n",
       "\n",
       "      scansWithoutRegistration  quantityModifications  \\\n",
       "1550                  0.222222           1.000000e-07   \n",
       "466                   0.111111           9.999999e-01   \n",
       "273                   0.222222           2.222222e-01   \n",
       "550                   0.611111           7.777778e-01   \n",
       "673                   0.111111           1.000000e-07   \n",
       "\n",
       "      scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "1550                   0.667904        0.483474                  0.389940   \n",
       "466                    0.490378        0.387489                  0.079365   \n",
       "273                    0.745408        0.394678                  0.704134   \n",
       "550                    0.624107        0.889571                  0.898635   \n",
       "673                    0.588309        0.889163                  0.890838   \n",
       "\n",
       "      totalScannedLineItems  \n",
       "1550               1.000000  \n",
       "466                0.925926  \n",
       "273                0.592593  \n",
       "550                0.074074  \n",
       "673                0.074074  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quant_scaled_y = df_train.fraud\n",
    "df_wo_frauds = df_train.drop(['fraud'], axis=1)\n",
    "heads = list(df_wo_frauds.columns.values)\n",
    "\n",
    "qt = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "df_quant_scaled_x = pd.DataFrame(qt.fit_transform(df_wo_frauds), columns=heads)\n",
    "#df_quant_scaled['fraud'] = df_s_y\n",
    "train_qs_x, val_qs_x, train_qs_y, val_qs_y = train_test_split(df_quant_scaled_x, df_quant_scaled_y, test_size=0.2)\n",
    "\n",
    "print(\"Shape of train data: \", train_qs_x.shape, \"Shape of val data: \", val_qs_x.shape)\n",
    "train_qs_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:  [ 70  10  70  45 -50] Scaled Data:  [30 75 65 50 15]\n",
      "Original Data:  [ 0.23255814  0.03322259  0.23255814  0.14950166 -0.16722408] Scaled Data:  [0.09933775 0.24916944 0.21666667 0.16666667 0.05      ]\n"
     ]
    }
   ],
   "source": [
    "lin_svc = SVC(kernel=\"linear\", C=50)\n",
    "res_train1 = cross_validate(lin_svc, train_x,train_y, scoring=own_scorer, cv=5,n_jobs=-1)['test_score']\n",
    "res_train2 = cross_validate(lin_svc, train_qs_x,train_qs_y, scoring=own_scorer, cv=5,n_jobs=-1)['test_score']\n",
    "res_n_train1 = cross_validate(lin_svc, train_x,train_y, scoring=own_scorer_normalized, cv=5,n_jobs=-1)['test_score']\n",
    "res_n_train2 = cross_validate(lin_svc, train_qs_x,train_qs_y, scoring=own_scorer_normalized, cv=5,n_jobs=-1)['test_score']\n",
    "print(\"Original Data: \", res_train1,\"Scaled Data: \", res_train2)\n",
    "print(\"Original Data: \", res_n_train1,\"Scaled Data: \", res_n_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"kernel\" : ['linear', 'rbf','poly'],\n",
    "    \"C\" : np.arange(1,500,10),\n",
    "    \"gamma\" : np.arange(1,100),   #lgorithm\" : [‘SAMME’, ‘SAMME.R’]\n",
    "    \"degree\" : np.arange(1,10),\n",
    "    \"shrinking\" : [True,False]\n",
    "}\n",
    "svc = SVC()\n",
    "grid_search_svc = GridSearchCV(svc, param_grid = param_grid, scoring = own_scorer, n_jobs=-1,verbose=1,cv=5,refit = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 19800 candidates, totalling 99000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c8497f049dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search_svc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search_svc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:  [40 65 50 40 30] Scaled Data:  [35  0 55 15 25]\n",
      "Original Data:  [0.13289037 0.21594684 0.16611296 0.13289037 0.10033445] Scaled Data:  [0.11627907 0.         0.18272425 0.05       0.08333333]\n"
     ]
    }
   ],
   "source": [
    "default_xgb = xgb.XGBClassifier(n_jobs=6, verbosity=2)\n",
    "res_train1 = cross_validate(default_xgb, train_x,train_y, scoring=own_scorer, cv=5,n_jobs=-1)['test_score']\n",
    "res_train2 = cross_validate(default_xgb, train_qs_x,train_qs_y, scoring=own_scorer, cv=5,n_jobs=-1)['test_score']\n",
    "res_n_train1 = cross_validate(default_xgb, train_x,train_y, scoring=own_scorer_normalized, cv=5,n_jobs=-1)['test_score']\n",
    "res_n_train2 = cross_validate(default_xgb, train_qs_x,train_qs_y, scoring=own_scorer_normalized, cv=5,n_jobs=-1)['test_score']\n",
    "print(\"Original Data: \", res_train1,\"Scaled Data: \", res_train2)\n",
    "print(\"Original Data: \", res_n_train1,\"Scaled Data: \", res_n_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = xgb.XGBClassifier(gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=452,objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:  [ 60  60 -15  30  20] Scaled Data:  [20 30 55 40 45]\n"
     ]
    }
   ],
   "source": [
    "res_train1 = cross_validate(xgbc, train_x,train_y, scoring=own_scorer, cv=5,n_jobs=-1)['test_score']\n",
    "res_train2 = cross_validate(xgbc, train_qs_x,train_qs_y, scoring=own_scorer, cv=5,n_jobs=-1)['test_score']\n",
    "print(\"Original Data: \", res_train1,\"Scaled Data: \", res_train2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch does not work very well with XGBboost. We need an alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier(tree_method='gpu_hist')\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": np.linspace(1, 1e-3, 20),\n",
    "    \"gamma\": np.linspace(1e-1, 100, 100), #\"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n",
    "    \"max_depth\": np.linspace(1, 10,10,dtype=int),  # default 3\n",
    "    \"n_estimators\": np.linspace(50, 750,300,dtype=int),  # default 100\n",
    "    \"colsample_bytree\" : np.linspace(0.1, 1,10)\n",
    "}\n",
    "grid_search_xgb = GridSearchCV(xgboost, param_grid = params, scoring = own_scorer, n_jobs=-1,verbose=1,cv=5)\n",
    "grid_search_xgb.fit(train_x,  train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data to DMatrix\n",
    "d_train = xgb.DMatrix(train_x, label=train_y)\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "#param['n_jobs'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "bst = xgb.train(param, d_train, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"683pt\" height=\"218pt\"\n",
       " viewBox=\"0.00 0.00 682.94 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-214 678.937,-214 678.937,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"341.544\" cy=\"-192\" rx=\"113.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.544\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">totalScannedLineItems&lt;18.5</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"201.544\" cy=\"-105\" rx=\"113.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"201.544\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">totalScannedLineItems&lt;17.5</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M314.218,-174.409C292.344,-161.129 261.48,-142.39 237.585,-127.882\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"239.165,-124.747 228.801,-122.549 235.532,-130.73 239.165,-124.747\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.044\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"444.544\" cy=\"-105\" rx=\"111.581\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"444.544\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">scansWithoutRegistration&lt;7</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M361.893,-174.207C377.411,-161.401 398.974,-143.607 416.183,-129.404\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"418.752,-131.823 424.237,-122.758 414.296,-126.424 418.752,-131.823\"/>\n",
       "<text text-anchor=\"middle\" x=\"406.544\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"69.5438\" cy=\"-18\" rx=\"69.5877\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"69.5438\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=&#45;1.0290544</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M173.634,-87.5521C164.032,-81.7894 153.256,-75.2058 143.544,-69 129.531,-60.0463 114.271,-49.819 101.269,-40.9569\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"102.9,-37.832 92.671,-35.072 98.9463,-43.6085 102.9,-37.832\"/>\n",
       "<text text-anchor=\"middle\" x=\"178.044\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"235.544\" cy=\"-18\" rx=\"78.7863\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.544\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=&#45;0.342374861</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M208.424,-86.799C213.125,-75.0474 219.449,-59.2383 224.807,-45.8421\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"228.209,-46.7601 228.674,-36.1754 221.71,-44.1603 228.209,-46.7601\"/>\n",
       "<text text-anchor=\"middle\" x=\"228.544\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"427.544\" cy=\"-18\" rx=\"78.7863\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"427.544\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=&#45;0.428888947</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M441.104,-86.799C438.776,-75.1626 435.653,-59.5479 432.991,-46.2368\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"436.372,-45.2948 430.979,-36.1754 429.508,-46.6677 436.372,-45.2948\"/>\n",
       "<text text-anchor=\"middle\" x=\"472.044\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"599.544\" cy=\"-18\" rx=\"75.2868\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"599.544\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">leaf=0.878025353</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M475.85,-87.5969C486.85,-81.7811 499.274,-75.1528 510.544,-69 527.708,-59.6291 546.611,-49.0471 562.565,-40.0391\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"564.601,-42.9083 571.582,-34.9382 561.154,-36.8156 564.601,-42.9083\"/>\n",
       "<text text-anchor=\"middle\" x=\"545.544\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f186045ac88>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.to_graphviz(bst, num_trees=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ab55b8a2009b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_search_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "xgbc = XGBClassifier(gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=452,objective='binary:logistic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
