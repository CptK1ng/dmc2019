{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n",
    "from scores import scores\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebooks/utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainandknn_Xy_original_df = pd.read_csv(\"../data/train_new.csv\", sep=\"|\")\n",
    "train_Xy_original_df, knn_Xy_original_df = train_test_split(trainandknn_Xy_original_df,train_size=0.75, random_state=42) # if FINAL_SUBMISSION else 0.8) #small\n",
    "test_X_original_df  = pd.read_csv(\"../data/test.csv\", sep=\"|\").iloc[0:500] #TODO: For faster testing we use less data from the test set\n",
    "test_final_X_df = pd.read_csv(\"../data/test.csv\", sep=\"|\")\n",
    "\n",
    "train_Xy_wo_knn_df = pd.read_csv(\"../data/train_new.csv\", sep=\"|\")\n",
    "\n",
    "#Only for test routines\n",
    "val_Xy_original_df = pd.read_csv(\"../data/val_new.csv\", sep=\"|\")\n",
    "train_complete_Xy_original_df = pd.read_csv(\"../data/train.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convention for variables names: datasetname_columntype_transformstatus_dataframeornot\n",
    "train_y_original_df = train_Xy_original_df[[\"fraud\"]].copy()\n",
    "train_X_original_df = train_Xy_original_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "knn_y_original_df = knn_Xy_original_df[[\"fraud\"]].copy()\n",
    "knn_X_original_df = knn_Xy_original_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "# Only for test routie#nes\n",
    "val_y_originial_df = val_Xy_original_df[[\"fraud\"]].copy()\n",
    "val_X_originial_df = val_Xy_original_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "train_y_wo_knn_df = train_Xy_wo_knn_df[[\"fraud\"]].copy()\n",
    "train_X_wo_knn_df = train_Xy_wo_knn_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "train_complete_y_originial_df = train_complete_Xy_original_df[[\"fraud\"]].copy()\n",
    "train_complete_X_originial_df = train_complete_Xy_original_df.copy().drop(\"fraud\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>totalScannedLineItems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.925130</td>\n",
       "      <td>0.240558</td>\n",
       "      <td>0.153259</td>\n",
       "      <td>0.449502</td>\n",
       "      <td>-1.558114</td>\n",
       "      <td>0.300299</td>\n",
       "      <td>-0.117812</td>\n",
       "      <td>-0.128310</td>\n",
       "      <td>-0.371627</td>\n",
       "      <td>1.559426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249301</td>\n",
       "      <td>-1.548098</td>\n",
       "      <td>-0.789781</td>\n",
       "      <td>-0.126199</td>\n",
       "      <td>-0.923450</td>\n",
       "      <td>0.886361</td>\n",
       "      <td>0.244945</td>\n",
       "      <td>0.043534</td>\n",
       "      <td>-0.282261</td>\n",
       "      <td>-0.173782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.249301</td>\n",
       "      <td>1.114087</td>\n",
       "      <td>0.410578</td>\n",
       "      <td>-0.701901</td>\n",
       "      <td>1.615204</td>\n",
       "      <td>1.472424</td>\n",
       "      <td>-0.185091</td>\n",
       "      <td>-0.137604</td>\n",
       "      <td>-0.379817</td>\n",
       "      <td>-0.289330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.512346</td>\n",
       "      <td>1.634045</td>\n",
       "      <td>1.450544</td>\n",
       "      <td>0.737353</td>\n",
       "      <td>-0.288787</td>\n",
       "      <td>0.886361</td>\n",
       "      <td>-0.158033</td>\n",
       "      <td>-0.128614</td>\n",
       "      <td>-0.345007</td>\n",
       "      <td>1.559426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.925130</td>\n",
       "      <td>-0.939274</td>\n",
       "      <td>1.078709</td>\n",
       "      <td>-0.701901</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>-0.285764</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>-0.010833</td>\n",
       "      <td>-0.472189</td>\n",
       "      <td>1.328332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0    0.925130                0.240558    0.153259       0.449502   \n",
       "1   -0.249301               -1.548098   -0.789781      -0.126199   \n",
       "2   -0.249301                1.114087    0.410578      -0.701901   \n",
       "3    1.512346                1.634045    1.450544       0.737353   \n",
       "4    0.925130               -0.939274    1.078709      -0.701901   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "0                 -1.558114               0.300299                  -0.117812   \n",
       "1                 -0.923450               0.886361                   0.244945   \n",
       "2                  1.615204               1.472424                  -0.185091   \n",
       "3                 -0.288787               0.886361                  -0.158033   \n",
       "4                  0.663209              -0.285764                   0.007505   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  totalScannedLineItems  \n",
       "0       -0.128310                 -0.371627               1.559426  \n",
       "1        0.043534                 -0.282261              -0.173782  \n",
       "2       -0.137604                 -0.379817              -0.289330  \n",
       "3       -0.128614                 -0.345007               1.559426  \n",
       "4       -0.010833                 -0.472189               1.328332  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "transformer = DataTransformer(scaler)\n",
    "\n",
    "# Adding new Features to train and test set\n",
    "train_X_unscaled_df = transformer.add_features(train_X_original_df)\n",
    "test_X_unscaled_df = transformer.add_features(test_X_original_df)\n",
    "knn_X_unscaled_df = transformer.add_features(knn_X_original_df)\n",
    "\n",
    "val_X_unscaled_df = transformer.add_features(val_X_originial_df)\n",
    "train_complete_X_unscaled_df = transformer.add_features(train_complete_X_originial_df) \n",
    "\n",
    "transformer.fit_scaler(transformer.add_features(train_complete_X_unscaled_df.append(test_X_unscaled_df, sort=False)))\n",
    "train_X_scaled_df = transformer.apply_scaler(train_X_unscaled_df)\n",
    "knn_X_scaled_df   = transformer.apply_scaler(knn_X_unscaled_df)\n",
    "\n",
    "\n",
    "test_X_scaled_df  = transformer.apply_scaler(test_X_unscaled_df)\n",
    "val_X_scaled_df = transformer.apply_scaler(val_X_unscaled_df)\n",
    "train_complete_X_scaled_df = transformer.apply_scaler(train_complete_X_unscaled_df)\n",
    "\n",
    "train_X_wo_knn_unscaled_df = transformer.add_features(train_X_wo_knn_df.copy())\n",
    "train_X_wo_knn_scaled_df = transformer.apply_scaler(train_X_wo_knn_unscaled_df)\n",
    "\n",
    "# labels\n",
    "train_y_df = train_y_original_df.copy()\n",
    "val_y_df = val_y_originial_df.copy()\n",
    "knn_y_df = knn_y_original_df.copy()\n",
    "\n",
    "train_complete_X_scaled_df = transformer.apply_scaler(transformer.add_features(train_complete_Xy_original_df.copy().drop(columns=['fraud'])))\n",
    "train_complete_y_df = train_complete_Xy_original_df.copy().fraud\n",
    "\n",
    "test_final_X_df = transformer.add_features(test_final_X_df)\n",
    "\n",
    "\n",
    "display(train_complete_X_scaled_df.head(5))\n",
    "display(train_complete_y_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring functions\n",
    "Defining multiple scores which should be tracked in the HyperParamSearch Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = scores.Scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'FBeta': metrics.make_scorer(metrics.fbeta_score, beta=0.5172), \"Precision\":'precision', \"Recall\": 'recall', \"AP\": score.average_precision, \"DMC\" : score.dmc_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the paramteres which should be tuned\n",
    "To tune the hyperparameters, i looked into the [documentation here](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster). `randint` can be used for integer values, for float values, use `uniform`. \n",
    "\n",
    "You can also use a Grid search on single parameters to get a feeling for a good interval. If you want to try only two possibilities, you can create a list like for the `scale_pos_weight` parameter.\n",
    "\n",
    "**Note: For the classifiers which work without gpu support, you can probably set a parameter n_jobs=-1 to use all processors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": randint(2, 6),  # default 3\n",
    "    \"n_estimators\": randint(200, 450),  # default 100\n",
    "    \"learnin_rate\" :  uniform(0.1, 0.7),\n",
    "    \"gamma\" : uniform(0,2),\n",
    "    \"min_child_weight\" : uniform(0,50),\n",
    "    \"max_delta_step\" : uniform(0,10), #Set it to value of 1-10 might help control the update.\n",
    "    \"reg_lambda\" : uniform(0.1,2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a classifier with some default values\n",
    "Not all paramters of a classifier should be fine tuned. For SVM for example, the `kernel`-paramter should be set manually. In the case of xgboost, some things like the objective, the booster and the tree method should not be tuned. The choice of paramters depend on the specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "default_xgb = XGBClassifier(booster=\"gbtree\",tree_method='gpu_hist', disable_default_eval_metric=1,objective='binary:logistic',eval_metric='aucpr', n_gpus=1, verbosity=2)\n",
    "search = RandomizedSearchCV(default_xgb, scoring=scoring, param_distributions=params, random_state=42, n_iter=500,\n",
    "                            cv=3, verbose=1, n_jobs=-1, return_train_score=True,refit='DMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6026 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8426 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9776 tasks      | elapsed: 18.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11226 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12776 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14426 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed: 27.7min finished\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(default_xgb, scoring=scoring, param_distributions=params, random_state=42, n_iter=5000,\n",
    "                            cv=3, verbose=1, n_jobs=-1, return_train_score=True,refit='DMC')\n",
    "search.fit(train_complete_X_scaled_df, train_complete_y_df)\n",
    "results = search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete_Xy_scaled_df = train_complete_X_scaled_df.copy()\n",
    "train_complete_Xy_scaled_df['fraud'] =train_complete_y_df.copy()\n",
    "\n",
    "train_Xy_wo_knn_scaled_df = train_X_wo_knn_scaled_df.copy()\n",
    "train_Xy_wo_knn_scaled_df['fraud'] = train_y_wo_knn_df\n",
    "\n",
    "val_Xy_scaled = val_X_scaled_df.copy()\n",
    "val_Xy_scaled['fraud'] = val_y_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Fix Split: \n",
      "DMC Score: -20  ---  Normalized DMC Score: -0.05319148936170213, \n",
      "\n",
      "Results Cross Validation: \n",
      "DMC Score: 42.0  ---  Normalized DMC Score: 0.11165248226950353 \n"
     ]
    }
   ],
   "source": [
    "scorings = {'AUC': 'roc_auc', 'FBeta': metrics.make_scorer(metrics.fbeta_score, beta=0.5172), \"Precision\":'precision', \"Recall\": 'recall', \"AP\": score.average_precision, \"DMC\" : score.dmc_score}\n",
    "xgbo = search.best_estimator_\n",
    "result_dict = test_classification(xgbo,df_train=train_Xy_wo_knn_scaled_df, df_val=val_Xy_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmc = np.mean(search.cv_results_['mean_test_DMC'])\n",
    "ap = np.mean(search.cv_results_['mean_test_AP'])\n",
    "precision = np.mean(search.cv_results_['mean_test_Precision'])\n",
    "recall = np.mean(search.cv_results_['mean_test_Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMC: -87.93675199574243 --- Average Precision: 0.844044914297449 --- Precision: 0.5144370515276927 --- Recall: 0.3709619890787609\n"
     ]
    }
   ],
   "source": [
    "print(\"DMC: {} --- Average Precision: {} --- Precision: {} --- Recall: {}\".format(dmc, ap, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, disable_default_eval_metric=1,\n",
       "       eval_metric='aucpr', gamma=0.8759954957911082,\n",
       "       learnin_rate=0.31522352112346824, learning_rate=0.1,\n",
       "       max_delta_step=9.849378689708635, max_depth=2,\n",
       "       min_child_weight=1.9153733419830676, missing=None, n_estimators=220,\n",
       "       n_gpus=1, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=0.11118831176373903,\n",
       "       scale_pos_weight=1, seed=None, silent=True, subsample=1,\n",
       "       tree_method='gpu_hist', verbosity=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.8759954957911082,\n",
       " 'learnin_rate': 0.31522352112346824,\n",
       " 'max_delta_step': 9.849378689708635,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 1.9153733419830676,\n",
       " 'n_estimators': 220,\n",
       " 'reg_lambda': 0.11118831176373903}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
