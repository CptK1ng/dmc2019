{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ggf muss Pfad angepasst werden\n",
    "os.chdir(\"{}/..\".format(os.getcwd()))\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, linear_model, metrics\n",
    "from scipy.stats import uniform, randint\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split, cross_validate\n",
    "#from scripts.utils import own_scorer, calc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/extended_train.csv\", sep=\"|\")\n",
    "sum_frauds, sum_non_frauds  = len(df_train[df_train.fraud == 1]), len(df_train[df_train.fraud == 0])\n",
    "df_y = df_train.fraud\n",
    "df_X = df_train.drop(['fraud'], axis=1)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(df_X, df_y, test_size=0.2)\n",
    "\n",
    "print(\"Shape of train data: \", train_x.shape, \"Shape of val data: \", val_x.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data with new Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train\n",
    "df['totalScannedLineItems'] = df['scannedLineItemsPerSecond'] * df['totalScanTimeInSeconds']\n",
    "df['avgTimePerScan'] = 1/ df['scannedLineItemsPerSecond']\n",
    "df['avgValuePerScan'] = df['avgTimePerScan'] * df['valuePerSecond']\n",
    "df['withoutRegisPerPosition'] = df['scansWithoutRegistration'] / df['totalScannedLineItems'] #equivalent to lineItemVoidsPerPosition?\n",
    "df['quantiModPerPosition'] = df['quantityModifications'] / df['totalScannedLineItems']\n",
    "df['lineItemVoidsPerTotal'] = df['lineItemVoids'] / df['grandTotal']\n",
    "df['withoutRegisPerTotal'] = df['scansWithoutRegistration'] / df['grandTotal']\n",
    "df['quantiModPerTotal'] = df['quantityModifications'] / df['grandTotal']\n",
    "df['lineItemVoidsPerTime'] = df['lineItemVoids'] / df['totalScanTimeInSeconds']\n",
    "df['withoutRegisPerTime'] = df['scansWithoutRegistration'] / df['totalScanTimeInSeconds']\n",
    "df['quantiModPerTime'] = df['quantityModifications'] / df['totalScanTimeInSeconds']\n",
    "df['valuePerScannedLineItem'] = df['valuePerSecond'] / df['scannedLineItemsPerSecond']\n",
    "df1_y = df.fraud\n",
    "df1_X = df.drop(['fraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Frauds: \", sum_frauds, \"Non Frauds: \", sum_non_frauds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'FBeta': metrics.make_scorer(metrics.fbeta_score, beta=0.5172)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": randint(2, 6),  # default 3\n",
    "    \"n_estimators\": randint(300, 450),  # default 100\n",
    "    \"eta\" :  uniform(0.1, 0.7),\n",
    "    \"gamma\" : uniform(0,2),\n",
    "    \"min_child_weight\" : uniform(0,50),\n",
    "    \"max_delta_step\" : uniform(0,10), #Set it to value of 1-10 might help control the update.\n",
    "    \"lambda\" : uniform(0.1,2),\n",
    "    \"scale_pos_weight\" : [1, sum_non_frauds/sum_frauds],\n",
    "    \"max_bin\" : randint(200, 300)\n",
    "}\n",
    "default_xgb = xgb.XGBClassifier(booster=\"gbtree\",tree_method='gpu_hist', disable_default_eval_metric=1,objective='binary:logistic',eval_metric='aucpr', n_jobs=-1, verbosity=2)\n",
    "search = RandomizedSearchCV(default_xgb, scoring=scoring, param_distributions=params, random_state=42, n_iter=10000,\n",
    "                            cv=3, verbose=1, n_jobs=-1, return_train_score=True,refit='FBeta')\n",
    "search.fit(df_X, df_y)\n",
    "results = search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_scorer_normalized(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    confusion_matrix = metrics.confusion_matrix(ground_truth, prediction)\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "    return dmc_score/len(ground_truth)\n",
    "\n",
    "# DMC Score for usage as scorer\n",
    "def own_scorer(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    confusion_matrix = metrics.confusion_matrix(ground_truth, prediction)\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "    return dmc_score\n",
    "\n",
    "scorings = {\"DMC\" : own_scorer, \"DMC_Norm\" : own_scorer_normalized}\n",
    "xgbo = search.best_estimator_\n",
    "res = cross_validate(xgbo, df_X, df_y, scoring=scorings, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
