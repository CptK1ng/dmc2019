{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(y_test, y_pred):\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    f2_score = (0 if all(y_pred == 0) else metrics.fbeta_score(y_test, y_pred, beta=2))\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "\n",
    "    return accuracy, f2_score, dmc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_scorer(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    confusion_matrix = metrics.confusion_matrix(ground_truth, prediction)\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "    return dmc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_scorer_normalized(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    confusion_matrix = metrics.confusion_matrix(ground_truth, prediction)\n",
    "    dmc_score = np.sum(confusion_matrix * np.array([[0, -25], [-5, 5]]))\n",
    "    return dmc_score/len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_f2_score(estimator, X_val, ground_truth):\n",
    "    prediction = estimator.predict(X_val)\n",
    "    return 0 if all(prediction == 0) else metrics.fbeta_score(ground_truth, prediction, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate],\n",
    "                results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_cross_validation(classifier, data, cv=5):\n",
    "    k = KFold(n_splits=cv)\n",
    "    splits = k.get_n_splits(data)\n",
    "    print(splits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your Classifier by multiple k fold cross validates and shuffles. Currently only sklearn familiar classifiers are allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification(classifier, df_train, df_val, predict_proba=True, ret_dataframe=True, ):\n",
    "    result = dict()\n",
    "    dmc_scores = list()\n",
    "    dmc_scores_norm = list()\n",
    "    res_dataframe = df_val.copy()\n",
    "    y_train = df_train.fraud\n",
    "    x_train = df_train.drop(columns=['fraud'])\n",
    "    y_val = df_val.fraud\n",
    "    x_val = df_val.drop(columns=['fraud'])\n",
    "    \n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    dmc_score = own_scorer(classifier, x_val, y_val)\n",
    "    dmc_norm = own_scorer_normalized(classifier, x_val, y_val)\n",
    "    res_dataframe['prediction'] = classifier.predict(x_val)\n",
    "    \n",
    "    if predict_proba:\n",
    "        res_dataframe['probablity'] = [round(max(x),3) for x in classifier.predict_proba(x_val)]\n",
    "    # Cross Validation\n",
    "    scorings = {\"DMC\" : own_scorer, \"DMC_Norm\" : own_scorer_normalized}\n",
    "\n",
    "    \n",
    "    x_train_complete = x_train.append(x_val)\n",
    "    y_train_complete = y_train.append(y_val)\n",
    "    cross_validation = cross_validate(classifier, x_train_complete,y_train_complete,scoring=scorings, cv=5)\n",
    "    cv_dmc_mean = sum(cross_validation['test_DMC'])/len(cross_validation['test_DMC'])\n",
    "    cv_dmc_norm_mean = sum(cross_validation['test_DMC_Norm'])/len(cross_validation['test_DMC_Norm'])\n",
    "    \n",
    "    result = {\"dmc_score\" : dmc_score, \"dmc_score_norm\" : dmc_norm, \"cv_dmc_score\": cv_dmc_mean,\"cv_dmc_score_norm\":cv_dmc_norm_mean}\n",
    "    if ret_dataframe:\n",
    "        result['dataframe'] = res_dataframe\n",
    "    print(\"Results Fix Split: \\nDMC Score: {}  ---  Normalized DMC Score: {}, \\n\\nResults Cross Validation: \\nDMC Score: {}  ---  Normalized DMC Score: {} \".format(dmc_score, dmc_norm, cv_dmc_mean,cv_dmc_norm_mean))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional features by calling this on the specific Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(dataframe):\n",
    "    dataframe['totalScannedItems'] = dataframe['scannedLineItemsPerSecond'] * dataframe['totalScanTimeInSeconds']\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale dataframe with Sklean Scaler (Please scale only model input \"train_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataframe(df, scaler):\n",
    "    df_tmp = pd.DataFrame()\n",
    "    tmp_data = scaler.transform(df[df.columns])\n",
    "    df_tmp[df.columns] = pd.DataFrame(tmp_data)\n",
    "    return df_tmp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find nearest neigbour to test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbor(row_scaled, dataset_scaled):  \n",
    "    diffs = [np.sum((row_scaled[0] - ds_row)**2) for ds_row in dataset_scaled]\n",
    "    idx = np.argmin(diffs)[0]\n",
    "    return idx, diffs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_classifier_for_sample(idx, validation_set):\n",
    "    ground_truth = validation_set.iloc[idx].fraud\n",
    "    \n",
    "    # Both classifier predicted the calue correctly\n",
    "    if (validation_set.iloc[idx].lsvc_predict == ground_truth) and (validation_set.iloc[idx].xgb_predict == ground_truth):\n",
    "        if validation_set.iloc[idx].lsvc_proba > validation_set.iloc[idx].xgb_proba:\n",
    "            return \"lsvc\"\n",
    "        else:\n",
    "            return \"xgboost\"\n",
    "    # lsvc predicted correctly\n",
    "    elif (validation_set.iloc[idx].lsvc_predict == ground_truth) and (validation_set.iloc[idx].xgb_predict != ground_truth):\n",
    "        return \"lsvc\"\n",
    "    \n",
    "    # xgboost predicted correcltly\n",
    "    elif (validation_set.iloc[idx].lsvc_predict != ground_truth) and (validation_set.iloc[idx].xgb_predict == ground_truth):\n",
    "        return \"xgboost\"\n",
    "    \n",
    "    # If No classifier predicted the knn correct, None is returned\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer:\n",
    "    \"\"\"\n",
    "    for scaling, data transformations (new features, one-hot encoding, categorical, ...)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, scaler):\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def fit_scaler(self, df):\n",
    "        df_tmp = df.copy()\n",
    "        self.scaler.fit(df_tmp.astype(np.float64))\n",
    "        return self\n",
    "        \n",
    "    def apply_scaler(self, df):\n",
    "        df_temp = df.copy()\n",
    "        return pd.DataFrame(self.scaler.transform(df_temp),df_temp.index, df_temp.columns)\n",
    "    \n",
    "    def inverse_scale(self, df):\n",
    "        df_tmp = df.copy()\n",
    "        return pd.DataFrame(self.scaler.inverse_transform(df_tmp), df_tmp.index, df_tmp.columns)\n",
    "    \n",
    "    def add_features(self,df):\n",
    "        #TODO: Choose relevant features\n",
    "        df_tmp = df.copy()\n",
    "        df_tmp['totalScannedLineItems'] = df_tmp['scannedLineItemsPerSecond'] * df_tmp['totalScanTimeInSeconds']\n",
    "        #df['avgTimePerScan'] = 1/ df['scannedLineItemsPerSecond']\n",
    "        #df['avgValuePerScan'] = df['avgTimePerScan'] * df['valuePerSecond']\n",
    "        #df['withoutRegisPerPosition'] = df['scansWithoutRegistration'] / df['totalScannedLineItems'] #equivalent to lineItemVoidsPerPosition?\n",
    "        #df['quantiModPerPosition'] = df['quantityModifications'] / df['totalScannedLineItems']\n",
    "        #df['lineItemVoidsPerTotal'] = df['lineItemVoids'] / df['grandTotal']\n",
    "        #df['withoutRegisPerTotal'] = df['scansWithoutRegistration'] / df['grandTotal']\n",
    "        #df['quantiModPerTotal'] = df['quantityModifications'] / df['grandTotal']\n",
    "        #df['lineItemVoidsPerTime'] = df['lineItemVoids'] / df['totalScanTimeInSeconds']\n",
    "        #df['withoutRegisPerTime'] = df['scansWithoutRegistration'] / df['totalScanTimeInSeconds']\n",
    "        #df['quantiModPerTime'] = df['quantityModifications'] / df['totalScanTimeInSeconds']\n",
    "        #df['valuePerScannedLineItem'] = df['valuePerSecond'] / df['scannedLineItemsPerSecond']\n",
    "        return df_tmp\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        All in one: Apply all transform methods\n",
    "            1.) addFeatures\n",
    "            2.) apply_scaler\n",
    "        \"\"\"\n",
    "        df_tmp = df.copy()\n",
    "        return self.apply_scaler(self.add_features(df_tmp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNLookup():\n",
    "\n",
    "    def __init__(self, knn_data):\n",
    "\n",
    "        #self.knn = NearestNeighbors(n_neighbors=1)\n",
    "        #self.knn.fit(knn_data.values.tolist())\n",
    "\n",
    "        self.tree = KDTree(knn_data)\n",
    "\n",
    "    def refit(self, knn_data):\n",
    "        self.tree = KDTree(knn_data)\n",
    "\n",
    "    def find_nearest_neighbor(self, row_scaled, dataset_scaled):\n",
    "        diffs = [np.sum((row_scaled - ds_row) ** 2) for idx, ds_row in dataset_scaled.iterrows()]\n",
    "        idx = np.argmin(diffs)\n",
    "        return idx, diffs[idx]\n",
    "\n",
    "    def find_nearest_neighbor2(self, row_scaled, dataset_scaled):\n",
    "        dist, ind = self.tree.query([row_scaled.values], k=1)\n",
    "        return np.ravel(ind)[0], np.ravel(dist)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_results_ssl(result_dict):\n",
    "    # recall = TP / (TP + FN)\n",
    "    # precision = TP / (TP + FP)\n",
    "\n",
    "    dmc_scores_val = {}\n",
    "    #dmc_scores_val = dict.fromkeys(['lin_svg', 'xgboost', 'own_classifier'])\n",
    "    dmc_scores_train = {}\n",
    "    precision_val = {}\n",
    "    precision_train = {}\n",
    "    recall_val = {}\n",
    "    recall_train = {}\n",
    "\n",
    "    for iteration_number, elem in enumerate(res):\n",
    "        iteration_dict = elem\n",
    "        #print(\"# Iteration: \", iteration_number, \"\\n# Value: \", iteration_dict)\n",
    "        for classifier, results in iteration_dict.items():\n",
    "            #print(\"\\t## Classifier: \", classifier, \"\\n\\t## Results: \", results)\n",
    "            for set_name, result in results.items():\n",
    "                conf_matrix = result['conf_matrix']\n",
    "                tp = conf_matrix[0][0]\n",
    "                fp = conf_matrix[0][1]\n",
    "                fn = conf_matrix[1][0]\n",
    "                tn = conf_matrix[1][1]\n",
    "\n",
    "                recall = tp / (tp + fn)\n",
    "                precision = tp / (tp + fp)\n",
    "\n",
    "                if set_name == \"val\":\n",
    "                    if classifier in dmc_scores_val:\n",
    "                        dmc_scores_val[classifier].append(result['dmc_score'])\n",
    "                    else:\n",
    "                        dmc_scores_val[classifier] = [result['dmc_score']]\n",
    "                    if classifier in recall_val:\n",
    "                        recall_val[classifier].append(recall)\n",
    "                    else:\n",
    "                        recall_val[classifier] = [recall]\n",
    "                    if classifier in precision_val:\n",
    "                        precision_val[classifier].append(precision)\n",
    "                    else:\n",
    "                        precision_val[classifier] = [precision]\n",
    "                else:\n",
    "                    if classifier in dmc_scores_train:\n",
    "                        dmc_scores_train[classifier].append(result['dmc_score'])\n",
    "                    else:\n",
    "                        dmc_scores_train[classifier] = [result['dmc_score']]\n",
    "                    if classifier in recall_train:\n",
    "                        recall_train[classifier].append(recall)\n",
    "                    else:\n",
    "                        recall_train[classifier] = [recall]\n",
    "                    if classifier in precision_train:\n",
    "                        precision_train[classifier].append(precision)\n",
    "                    else:\n",
    "                        precision_train[classifier] = [precision]\n",
    "                #print(\"\\t\\t### Set: \", set_name, \"\\n\\t\\t### Result: \", result)\n",
    "                #print(\"TP: \", tp, \"\\tFP: \", fp, \"\\tFN: \", fn, \"\\tTN: \", tn)\n",
    "\n",
    "\n",
    "    #print(dmc_scores_val)\n",
    "    #print(dmc_scores_train)\n",
    "    #print(precision_val)\n",
    "    #print(precision_train)\n",
    "    #print(recall_val)\n",
    "    #print(recall_train)\n",
    "\n",
    "    plt.figure(num=1, figsize=(7,7))\n",
    "    plt.subplot(311)\n",
    "    plt.plot(dmc_scores_train['lin_svc'], label='lin_svc', color='r')# Entwicklung der Lin SVC)\n",
    "    plt.plot(dmc_scores_train['xgboost'], label='xgboost', color='b')# Entwicklung der Lin SVC)\n",
    "    plt.plot(dmc_scores_train['own_classifier'], label='own_classifier', color='g')# Entwicklung der Lin SVC)\n",
    "    plt.title('DMC Score on the train set')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    plt.subplot(312)\n",
    "    plt.plot(precision_train['lin_svc'], label='lin_svc', color='r')# Entwicklung der Lin SVC)\n",
    "    plt.plot(precision_train['xgboost'], label='xgboost', color='b')# Entwicklung der Lin SVC)\n",
    "    plt.plot(precision_train['own_classifier'], label='own_classifier', color='g')# Entwicklung der Lin SVC)\n",
    "    plt.title('Precision on the train set')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    plt.subplot(313)\n",
    "    plt.plot(recall_train['lin_svc'], label='lin_svc', color='r')# Entwicklung der Lin SVC)\n",
    "    plt.plot(recall_train['xgboost'], label='xgboost', color='b')# Entwicklung der Lin SVC)\n",
    "    plt.plot(recall_train['own_classifier'], label='own_classifier', color='g')# Entwicklung der Lin SVC)\n",
    "    plt.title('Recall on the train set')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend()\n",
    "    plt.subplots_adjust(left=0.0, right=1.0, bottom=2.0, top=3.5)\n",
    "    #plt.show()\n",
    "\n",
    "    plt.figure(2, figsize=(7,7))\n",
    "    plt.subplot(311)\n",
    "    plt.plot(dmc_scores_val['lin_svc'], label='lin_svc', color='r')# Entwicklung der Lin SVC)\n",
    "    plt.plot(dmc_scores_val['xgboost'], label='xgboost', color='b')# Entwicklung der Lin SVC)\n",
    "    plt.plot(dmc_scores_val['own_classifier'], label='own_classifier', color='g')# Entwicklung der Lin SVC)\n",
    "    plt.title('DMC Score on the val set')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    plt.subplot(312)\n",
    "    plt.plot(precision_val['lin_svc'], label='lin_svc', color='r')# Entwicklung der Lin SVC)\n",
    "    plt.plot(precision_val['xgboost'], label='xgboost', color='b')# Entwicklung der Lin SVC)\n",
    "    plt.plot(precision_val['own_classifier'], label='own_classifier', color='g')# Entwicklung der Lin SVC)\n",
    "    plt.title('Precision on the val set')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "\n",
    "    plt.subplot(313)\n",
    "    plt.plot(recall_val['lin_svc'], label='lin_svc', color='r')# Entwicklung der Lin SVC)\n",
    "    plt.plot(recall_val['xgboost'], label='xgboost', color='b')# Entwicklung der Lin SVC)\n",
    "    plt.plot(recall_val['own_classifier'], label='own_classifier', color='g')# Entwicklung der Lin SVC)\n",
    "    plt.title('Recall on the val set')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplots_adjust(left=0.0, right=1.0, bottom=2.0, top=3.5)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
