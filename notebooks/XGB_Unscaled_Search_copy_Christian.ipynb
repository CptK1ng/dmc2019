{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n",
    "#from scores import scores\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebooks/utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainandknn_Xy_original_df = pd.read_csv(\"../data/train_new.csv\", sep=\"|\")\n",
    "train_Xy_original_df, knn_Xy_original_df = train_test_split(trainandknn_Xy_original_df,train_size=0.75, random_state=42) # if FINAL_SUBMISSION else 0.8) #small\n",
    "test_X_original_df  = pd.read_csv(\"../data/test.csv\", sep=\"|\").iloc[0:500] #TODO: For faster testing we use less data from the test set\n",
    "test_final_X_df = pd.read_csv(\"../data/test.csv\", sep=\"|\")\n",
    "\n",
    "train_Xy_wo_knn_df = pd.read_csv(\"../data/train_new.csv\", sep=\"|\")\n",
    "\n",
    "#Only for test routines\n",
    "val_Xy_original_df = pd.read_csv(\"../data/val_new.csv\", sep=\"|\")\n",
    "train_complete_Xy_original_df = pd.read_csv(\"../data/train.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convention for variables names: datasetname_columntype_transformstatus_dataframeornot\n",
    "train_y_original_df = train_Xy_original_df[[\"fraud\"]].copy()\n",
    "train_X_original_df = train_Xy_original_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "knn_y_original_df = knn_Xy_original_df[[\"fraud\"]].copy()\n",
    "knn_X_original_df = knn_Xy_original_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "# Only for test routie#nes\n",
    "val_y_originial_df = val_Xy_original_df[[\"fraud\"]].copy()\n",
    "val_X_originial_df = val_Xy_original_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "train_Xy_wo_knn_df = train_Xy_wo_knn_df.drop(train_Xy_wo_knn_df[train_Xy_wo_knn_df.trustLevel >= 3].index)\n",
    "\n",
    "train_y_wo_knn_df = train_Xy_wo_knn_df[[\"fraud\"]].copy()\n",
    "train_X_wo_knn_df = train_Xy_wo_knn_df.copy().drop(\"fraud\", axis=1)\n",
    "\n",
    "train_complete_y_originial_df = train_complete_Xy_original_df[[\"fraud\"]].copy()\n",
    "train_complete_X_originial_df = train_complete_Xy_original_df.copy().drop(\"fraud\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>totalScannedLineItems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1545</td>\n",
       "      <td>22.80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>725</td>\n",
       "      <td>41.08</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.056662</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>32.45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>25.50</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "5            1                     770       11.09             11   \n",
       "7            2                    1545       22.80              0   \n",
       "9            2                     725       41.08             10   \n",
       "15           1                     870       32.45              3   \n",
       "23           2                     125       25.50              5   \n",
       "\n",
       "    scansWithoutRegistration  quantityModifications  \\\n",
       "5                          5                      2   \n",
       "7                          8                      4   \n",
       "9                          2                      4   \n",
       "15                         1                      5   \n",
       "23                         6                      2   \n",
       "\n",
       "    scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "5                    0.033766        0.014403                  0.423077   \n",
       "7                    0.006472        0.014757                  0.000000   \n",
       "9                    0.037241        0.056662                  0.370370   \n",
       "15                   0.006897        0.037299                  0.500000   \n",
       "23                   0.192000        0.204000                  0.208333   \n",
       "\n",
       "    totalScannedLineItems  \n",
       "5                    26.0  \n",
       "7                    10.0  \n",
       "9                    27.0  \n",
       "15                    6.0  \n",
       "23                   24.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5     1\n",
       "7     0\n",
       "9     0\n",
       "15    0\n",
       "23    0\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "transformer = DataTransformer(scaler)\n",
    "\n",
    "# Adding new Features to train and test set\n",
    "train_X_unscaled_df = transformer.add_features(train_X_original_df)\n",
    "test_X_unscaled_df = transformer.add_features(test_X_original_df)\n",
    "knn_X_unscaled_df = transformer.add_features(knn_X_original_df)\n",
    "\n",
    "val_X_unscaled_df = transformer.add_features(val_X_originial_df)\n",
    "train_complete_X_unscaled_df = transformer.add_features(train_complete_X_originial_df) \n",
    "\n",
    "transformer.fit_scaler(transformer.add_features(train_complete_X_unscaled_df.append(test_X_unscaled_df, sort=False)))\n",
    "train_X_scaled_df = transformer.apply_scaler(train_X_unscaled_df)\n",
    "knn_X_scaled_df   = transformer.apply_scaler(knn_X_unscaled_df)\n",
    "\n",
    "\n",
    "test_X_scaled_df  = transformer.apply_scaler(test_X_unscaled_df)\n",
    "val_X_scaled_df = transformer.apply_scaler(val_X_unscaled_df)\n",
    "train_complete_X_scaled_df = transformer.apply_scaler(train_complete_X_unscaled_df)\n",
    "\n",
    "train_X_wo_knn_unscaled_df = transformer.add_features(train_X_wo_knn_df.copy())\n",
    "train_X_wo_knn_scaled_df = transformer.apply_scaler(train_X_wo_knn_unscaled_df)\n",
    "\n",
    "# labels\n",
    "train_y_df = train_y_original_df.copy()\n",
    "val_y_df = val_y_originial_df.copy()\n",
    "knn_y_df = knn_y_original_df.copy()\n",
    "\n",
    "train_complete_X_scaled_df = transformer.apply_scaler(transformer.add_features(train_complete_Xy_original_df.copy().drop(columns=['fraud'])))\n",
    "train_complete_y_df = train_complete_Xy_original_df.copy().fraud\n",
    "train_complete_X_unscaled_df = transformer.add_features(train_complete_Xy_original_df.copy().drop(columns=['fraud']))\n",
    "\n",
    "test_final_X_df = transformer.add_features(test_final_X_df)\n",
    "\n",
    "\n",
    "train_complete_y_df = train_complete_y_df.drop(train_complete_X_unscaled_df[train_complete_X_unscaled_df.trustLevel >= 3].index)\n",
    "train_complete_X_unscaled_df = train_complete_X_unscaled_df.drop(train_complete_X_unscaled_df[train_complete_X_unscaled_df.trustLevel >= 3].index)\n",
    "\n",
    "display(train_complete_X_unscaled_df.head(5))\n",
    "display(train_complete_y_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring functions\n",
    "Defining multiple scores which should be tracked in the HyperParamSearch Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = scores.Scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'FBeta': metrics.make_scorer(metrics.fbeta_score, beta=0.5172), \"Precision\":'precision', \"Recall\": 'recall'}#, \"AP\": score.average_precision, \"DMC\" : score.dmc_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the paramteres which should be tuned\n",
    "To tune the hyperparameters, i looked into the [documentation here](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster). `randint` can be used for integer values, for float values, use `uniform`. \n",
    "\n",
    "You can also use a Grid search on single parameters to get a feeling for a good interval. If you want to try only two possibilities, you can create a list like for the `scale_pos_weight` parameter.\n",
    "\n",
    "**Note: For the classifiers which work without gpu support, you can probably set a parameter n_jobs=-1 to use all processors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": randint(2, 6),  # default 3\n",
    "    \"n_estimators\": randint(200, 450),  # default 100\n",
    "    \"learnin_rate\" :  uniform(0.1, 0.7),\n",
    "    \"gamma\" : uniform(0,2),\n",
    "    \"min_child_weight\" : uniform(0,50),\n",
    "    \"max_delta_step\" : uniform(0,10), #Set it to value of 1-10 might help control the update.\n",
    "    \"reg_lambda\" : uniform(0.1,2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a classifier with some default values\n",
    "Not all paramters of a classifier should be fine tuned. For SVM for example, the `kernel`-paramter should be set manually. In the case of xgboost, some things like the objective, the booster and the tree method should not be tuned. The choice of paramters depend on the specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "default_xgb = XGBClassifier(booster=\"gbtree\",tree_method='gpu_hist', disable_default_eval_metric=1,objective='binary:logistic',eval_metric='aucpr', n_gpus=1, verbosity=2)\n",
    "search = RandomizedSearchCV(default_xgb, scoring=scoring, param_distributions=params, random_state=42, n_iter=500,\n",
    "                            cv=3, verbose=1, n_jobs=-1, return_train_score=True,refit='DMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10000 candidates, totalling 30000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 24.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 40.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 56.4min\n",
      "[Parallel(n_jobs=-1)]: Done 22034 tasks      | elapsed: 62.1min\n",
      "[Parallel(n_jobs=-1)]: Done 24184 tasks      | elapsed: 68.1min\n",
      "[Parallel(n_jobs=-1)]: Done 26434 tasks      | elapsed: 74.3min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 80.8min\n",
      "[Parallel(n_jobs=-1)]: Done 30000 out of 30000 | elapsed: 84.2min finished\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(default_xgb, scoring=scoring, param_distributions=params, random_state=42, n_iter=10000,\n",
    "                            cv=3, verbose=1, n_jobs=-1, return_train_score=True,refit='AUC')\n",
    "search.fit(train_complete_X_unscaled_df, train_complete_y_df)\n",
    "results = search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5361394269637965,\n",
       " 'learnin_rate': 0.5259503267995072,\n",
       " 'max_delta_step': 2.809035999095031,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 0.9672585190973582,\n",
       " 'n_estimators': 403,\n",
       " 'reg_lambda': 0.16439595189061076}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_complete_Xy_scaled_df = train_complete_X_scaled_df.copy()\n",
    "train_complete_Xy_scaled_df['fraud'] =train_complete_y_df.copy()\n",
    "\n",
    "train_Xy_wo_knn_scaled_df = train_X_wo_knn_scaled_df.copy()\n",
    "train_Xy_wo_knn_scaled_df['fraud'] = train_y_wo_knn_df\n",
    "\n",
    "val_Xy_scaled = val_X_scaled_df.copy()\n",
    "val_Xy_scaled['fraud'] = val_y_df.copy()\n",
    "\n",
    "# need to cut trustLevel >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1503,11) (10,) (1503,11) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5d2e0436468f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_inverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Xy_wo_knn_scaled_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_inverse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-24d28185cf3d>\u001b[0m in \u001b[0;36minverse_scale\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdf_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    821\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1503,11) (10,) (1503,11) "
     ]
    }
   ],
   "source": [
    "test_inverse = transformer.inverse_scale(train_Xy_wo_knn_scaled_df.copy())\n",
    "test_inverse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Fix Split: \n",
      "DMC Score: 15  ---  Normalized DMC Score: 0.0398936170212766, \n",
      "\n",
      "Results Cross Validation: \n",
      "DMC Score: 49.0  ---  Normalized DMC Score: 0.1303191489361702 \n"
     ]
    }
   ],
   "source": [
    "scorings = {'AUC': 'roc_auc', 'FBeta': metrics.make_scorer(metrics.fbeta_score, beta=0.5172), \"Precision\":'precision', \"Recall\": 'recall'}#, \"AP\": score.average_precision, \"DMC\" : score.dmc_score}\n",
    "xgbo = search.best_estimator_\n",
    "result_dict = test_classification(xgbo,df_train=train_Xy_wo_knn_scaled_df, df_val=val_Xy_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmc = np.mean(search.cv_results_['mean_test_DMC'])\n",
    "#ap = np.mean(search.cv_results_['mean_test_AP'])\n",
    "#precision = np.mean(search.cv_results_['mean_test_Precision'])\n",
    "#recall = np.mean(search.cv_results_['mean_test_Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMC: -87.93675199574243 --- Average Precision: 0.844044914297449 --- Precision: 0.5144370515276927 --- Recall: 0.3709619890787609\n"
     ]
    }
   ],
   "source": [
    "#print(\"DMC: {} --- Average Precision: {} --- Precision: {} --- Recall: {}\".format(dmc, ap, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, disable_default_eval_metric=1,\n",
       "       eval_metric='aucpr', gamma=0.5361394269637965,\n",
       "       learnin_rate=0.5259503267995072, learning_rate=0.1,\n",
       "       max_delta_step=2.809035999095031, max_depth=2,\n",
       "       min_child_weight=0.9672585190973582, missing=None, n_estimators=403,\n",
       "       n_gpus=1, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=0.16439595189061076,\n",
       "       scale_pos_weight=1, seed=None, silent=True, subsample=1,\n",
       "       tree_method='gpu_hist', verbosity=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5361394269637965,\n",
       " 'learnin_rate': 0.5259503267995072,\n",
       " 'max_delta_step': 2.809035999095031,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 0.9672585190973582,\n",
       " 'n_estimators': 403,\n",
       " 'reg_lambda': 0.16439595189061076}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
