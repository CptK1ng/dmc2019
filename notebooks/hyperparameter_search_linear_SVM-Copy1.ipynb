{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Finetuning with RandomizedSeachCV\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ggf muss Pfad angepasst werden\n",
    "os.chdir(\"{}/..\".format(os.getcwd()))\n",
    "os.getcwd()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, linear_model, metrics, svm\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebooks/utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Loading the whole training set and adding the column \"totalScannedItems\" by calling `add_new_features` defined in utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\", sep=\"|\")\n",
    "df = add_new_features(df)\n",
    "sum_frauds, sum_non_frauds  = len(df[df.fraud == 1]), len(df[df.fraud == 0])\n",
    "train_y = df.fraud\n",
    "train_x = df.drop(columns=['fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data for validation\n",
    "df_fit = pd.read_csv(\"data/train_new.csv\", sep=\"|\")\n",
    "df_fit = add_new_features(df_fit)\n",
    "df_fit_y = df_fit.fraud\n",
    "df_fit_x = df_fit.drop(columns=['fraud'])\n",
    "\n",
    "# Validation Data\n",
    "df_val = pd.read_csv(\"data/val_new.csv\", sep=\"|\")\n",
    "df_val = add_new_features(df_val)\n",
    "df_val_y = df_val.fraud\n",
    "df_val_x = df_val.drop(columns=['fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_df(df, scaler):\n",
    "    df_tmp = pd.DataFrame()\n",
    "    tmp_data = scaler.fit_transform(df[df.columns])\n",
    "    df_tmp[df.columns] = pd.DataFrame(tmp_data)\n",
    "    return df_tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lukas/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lukas/Projects/dmc2019/venv/lib/python3.5/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train_c_norm = scale_df(train_x, MinMaxScaler())\n",
    "train_test = scale_df(df_fit_x, MinMaxScaler())\n",
    "val_test =  scale_df(df_val_x, MinMaxScaler())\n",
    "train_test['fraud'] =df_fit.fraud\n",
    "val_test['fraud'] = df_val.fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring functions\n",
    "Defining multiple scores which should be tracked in the HyperParamSearch Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'FBeta': metrics.make_scorer(metrics.fbeta_score, beta=0.5172)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the paramteres which should be tuned\n",
    "To tune the hyperparameters, i looked into the [documentation here](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster). `randint` can be used for integer values, for float values, use `uniform`. \n",
    "\n",
    "You can also use a Grid search on single parameters to get a feeling for a good interval. If you want to try only two possibilities, you can create a list like for the `scale_pos_weight` parameter.\n",
    "\n",
    "**Note: For the classifiers which work without gpu support, you can probably set a parameter n_jobs=-1 to use all processors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"tol\": uniform(1e-7, 1e-3),  # default 100\n",
    "    \"C\" :  uniform(0.0, 80.0),\n",
    "    \"shrinking\" : [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a classifier with some default values\n",
    "Not all paramters of a classifier should be fine tuned. For SVM for example, the `kernel`-paramter should be set manually. In the case of xgboost, some things like the objective, the booster and the tree method should not be tuned. The choice of paramters depend on the specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tol', 'decision_function_shape', 'probability', 'cache_size', 'kernel', 'coef0', 'degree', 'random_state', 'max_iter', 'shrinking', 'C', 'verbose', 'gamma', 'class_weight'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_svm = svm.SVC(kernel=\"linear\", probability=True, cache_size=8000,  verbose=0, random_state=None)\n",
    "default_svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some RandomizedSeach parameters\n",
    "- cv = cross validation: 3 is the standard value. This is enough and should not be touched\n",
    "- param_distribution: The params defined two cells above\n",
    "- scorer: The Scorere defined under \"scoring functions\" AUC and Fbeta are currently the best.\n",
    "- return_train_score: Doesnt affect the hyper param search\n",
    "- refit : Here, you can adress a score with the name, given in the dictionary. \n",
    "- n_jobs : -1 to use all cpus\n",
    "- n_iter : depends on number of params. For 9 params, i suggest a value above 20k. For less paramters 10k could be a good value.\n",
    "\n",
    "Further informations: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1632 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:   21.7s finished\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(default_svm, scoring=scoring, param_distributions=params, random_state=42, n_iter=10000,\n",
    "                            cv=3, verbose=1, n_jobs=-1, return_train_score=True,refit='AUC')\n",
    "search.fit(train_c_norm, train_y)\n",
    "results = search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DMC Score Reached: 45 ---  Normalized score: 0.1196808510638298\n"
     ]
    }
   ],
   "source": [
    "scorings = {\"DMC\" : own_scorer, \"DMC_Norm\" : own_scorer_normalized}\n",
    "xgbo = search.best_estimator_\n",
    "result_dict = test_classification(xgbo,df_train=train_test, df_val=val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMC Mean for CrossVal: 55.0 ---- DMC Normalized Mean for CrossVal: 0.1463900709219858\n"
     ]
    }
   ],
   "source": [
    "cv = cross_validate(xgbo, train_c_norm, train_y, scoring=scorings, cv=5, n_jobs=-1)\n",
    "mean_dmc = sum(cv['test_DMC'])/len(cv['test_DMC'])\n",
    "mean_dmc_n = sum(cv['test_DMC_Norm'])/len(cv['test_DMC_Norm'])\n",
    "print(\"DMC Mean for CrossVal: {} ---- DMC Normalized Mean for CrossVal: {}\".format(mean_dmc, mean_dmc_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show false predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>totalScannedItems</th>\n",
       "      <th>fraud</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.952591</td>\n",
       "      <td>0.785865</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.011107</td>\n",
       "      <td>0.020210</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471885</td>\n",
       "      <td>0.418833</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.016460</td>\n",
       "      <td>0.021582</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.796582</td>\n",
       "      <td>0.398354</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.727638</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>0.035433</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "97          0.4                0.952591    0.785865       0.818182   \n",
       "134         0.0                0.471885    0.418833       0.272727   \n",
       "312         0.2                0.796582    0.398354       0.545455   \n",
       "353         0.0                0.500000    0.727638       0.454545   \n",
       "\n",
       "     scansWithoutRegistration  quantityModifications  \\\n",
       "97                        0.8                    0.8   \n",
       "134                       1.0                    0.8   \n",
       "312                       0.9                    0.2   \n",
       "353                       0.9                    0.6   \n",
       "\n",
       "     scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "97                    0.011107        0.020210                  0.030000   \n",
       "134                   0.016460        0.021582                  0.013636   \n",
       "312                   0.011046        0.012213                  0.024000   \n",
       "353                   0.014808        0.035433                  0.023810   \n",
       "\n",
       "     totalScannedItems  fraud  prediction  probablity  \n",
       "97            1.000000      0           1       0.535  \n",
       "134           0.724138      0           1       0.506  \n",
       "312           0.827586      1           0       0.607  \n",
       "353           0.689655      1           0       0.568  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = result_dict['dataframe']\n",
    "res_df[(res_df.prediction != res_df.fraud)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=56.98164719395536, cache_size=8000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.00028494049437746764, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "| test      | DMC | DMC Normmalized    |\n",
    "|-----------|-----|--------------------|\n",
    "| Train/Val | 45  | 0.1196808510638298 |\n",
    "| Cross Val | 55  | 0.1463900709219858 |\n",
    "\n",
    "\n",
    "\n",
    "achieved with the following estimator settings:\n",
    "\n",
    "``` python\n",
    "SVC(C=56.98164719395536, cache_size=8000, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
    "  shrinking=True, tol=0.00028494049437746764, verbose=0)\n",
    "```     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_validate(estimator=xgbo, X=train_x, y=train_y, cv=5, scoring=own_scorer)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
